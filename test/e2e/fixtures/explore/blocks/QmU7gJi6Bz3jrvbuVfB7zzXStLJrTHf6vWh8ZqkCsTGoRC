
µ­"""Python script archiving the Project Apollo Archive's flickr albums.

This is a Python 3 script written using the flickrapi to automate the process
of backing up the Project Apollo Archive's flickr albums and metadata.

The folders for each album are base64 encoded in order to handle/preserve
characters that cannot be used in directory names.

Before running the script, you must set the api_key and api_secret variables
for a valid Flickr API. They can be obtained at the following URL:
https://www.flickr.com/services/apps/create/apply/.

Written by John Reed - https://github.com/leerspace
"""

import flickrapi
import os
import urllib.request
from xml.etree import ElementTree
import base64
import time
import sys
import json

api_key = ''  # NEEDS TO BE SET
api_secret = ''  # NEEDS TO BE SET
flickr_id = '136485307@N06'  # Flickr ID for the Project Apollo Archive
data_directory = 'albums'  # output directory

if api_key == '' or api_secret == '':
    print("api_key and api_secret must be set in the script before it can be run.")
    sys.exit()

flickr = flickrapi.FlickrAPI(api_key, api_secret, cache=True)

sets = flickr.photosets_getList(user_id=flickr_id)

# create directory for output if necessary
if not os.path.exists(os.path.join(data_directory)):
    os.makedirs(os.path.join(data_directory))

counter = 0  # file counter

# process each set for the user
for set in sets.getchildren()[0]:
    title = set.getchildren()[0].text

    print("Getting photos for set: " + str(title))
    title = str(base64.urlsafe_b64encode(bytearray(title, encoding='utf-8')),
                'utf-8')

    # create directory for this album if necessary
    if not os.path.exists(os.path.join(data_directory, title)):
        os.makedirs(os.path.join(data_directory, title))

    # save descriptions
    set_meta_path = os.path.join(data_directory, title, '_meta.xml')
    if not os.path.exists(set_meta_path):
        f = open(set_meta_path, 'w')
        f.write(ElementTree.tostring(set, encoding='unicode', method='xml'))
        f.close()

    # process each photo in the set
    for photo in flickr.walk_set(set.get('id')):
        counter += 1
        print("Image #" + str(counter))
        photo_id = photo.get('id')
        sizes = flickr.photos_getSizes(photo_id=photo_id)
        # get largest image, 'Original' is last
        photo_uri = sizes.find('sizes').findall('size')[-1].attrib['source']
        # extension = photo_uri.split('.')[-1]
        print("URL: " + photo_uri)
        # use photo filename from flickr
        photo_filename = os.path.basename(photo_uri)
        # print(photo_filename)

        # don't download image if it already exists
        photo_filepath = os.path.join(data_directory, title, photo_filename)
        if not os.path.isfile(photo_filepath):
            print("Saving photo: " + photo_filename + '\n\tfrom ' + photo_uri)
            urllib.request.urlretrieve(photo_uri, photo_filepath)

        # save photo metadata
        photo_meta_path = os.path.join(data_directory,
                                       title, photo_filename + '.xml')
        if not os.path.isfile(photo_meta_path):
            print("Saving photo metadata: " + photo_filename + '.xml')
            f = open(photo_meta_path, 'w')
            f.write(ElementTree.tostring(flickr.photos_getInfo(photo_id=photo_id), encoding='unicode', method='xml'))
            f.close()
        print()
        time.sleep(2)  # prevent overwhelming 3600/hr API limit

# write out metadata for archive
license = {'summary': 'Public Domain',
           'source': r'https://www.nasa.gov/multimedia/guidelines/index.html'}

metadata = {'title': 'Project Apollo Archive',
            'source': r'https://www.flickr.com/photos/projectapolloarchive/',
            'license': license,
            'last_update': int(time.time())}

f = open('_Metadata.json', 'w')
f.write(json.dumps(metadata))
f.close()
­